{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": "# Customer Churn Prediction \u2014 Full Analysis Pipeline\n> **Telco Customer Churn Dataset** | EDA \u00b7 Machine Learning \u00b7 Feature Importance \u00b7 Business Insights\n\nThis notebook covers:\n1. Data loading & preprocessing\n2. Exploratory Data Analysis (EDA)\n3. Model training \u2014 Logistic Regression & Random Forest\n4. Model evaluation (accuracy, precision, recall, F1, ROC-AUC)\n5. Feature importance analysis\n6. Business recommendations"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-0",
   "metadata": {},
   "source": "## 0. Imports & Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    roc_curve, classification_report\n)\nimport warnings, json, os, pickle\nwarnings.filterwarnings('ignore')\n\n# Style\nPALETTE = {'No': '#3B82F6', 'Yes': '#EF4444'}\nBG   = '#0F172A'\nTEXT = '#F8FAFC'\nplt.rcParams.update({\n    'figure.facecolor': BG, 'axes.facecolor': '#1E293B',\n    'axes.edgecolor': '#334155', 'text.color': TEXT,\n    'xtick.color': TEXT, 'ytick.color': TEXT,\n    'axes.labelcolor': TEXT, 'grid.color': '#334155',\n    'axes.spines.top': False, 'axes.spines.right': False,\n})\nprint('Libraries loaded \u2713')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-1",
   "metadata": {},
   "source": "## 1. Data Loading & Preprocessing\n\n### Steps:\n- Load the Telco churn CSV\n- Handle missing values in `TotalCharges`\n- Drop non-predictive columns (`customerID`)\n- Engineer new features: `TenureGroup`, `ChargePerMonth`, `HighValue`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load",
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_csv('../data/telco_churn.csv')\nprint(f'Shape: {df.shape}')\nprint(f'\\nMissing values:')\nprint(df.isnull().sum()[df.isnull().sum() > 0])\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-clean",
   "metadata": {},
   "outputs": [],
   "source": "# Fix TotalCharges (coerce blanks to NaN, fill with median)\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\ndf['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n\n# Drop customerID\ndf.drop('customerID', axis=1, inplace=True)\n\n# Feature engineering\ndf['TenureGroup'] = pd.cut(\n    df['tenure'],\n    bins=[0, 12, 24, 48, 72],\n    labels=['0-12mo', '13-24mo', '25-48mo', '49-72mo']\n)\ndf['ChargePerMonth'] = df['TotalCharges'] / (df['tenure'] + 1)\ndf['HighValue'] = (df['MonthlyCharges'] > df['MonthlyCharges'].quantile(0.75)).astype(int)\n\nprint(f'Churn rate: {(df[\"Churn\"]==\"Yes\").mean():.2%}')\nprint(f'Dataset after cleaning: {df.shape}')\ndf.describe().round(2)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-2",
   "metadata": {},
   "source": "## 2. Exploratory Data Analysis (EDA)\n\nWe investigate 6 key hypotheses:\n- Does churn vary by **contract type**?\n- Do **shorter-tenure** customers churn more?\n- Does **monthly charge** level predict churn?\n- Does **internet service type** affect churn?\n- How are variables **correlated** with each other?\n- What's the overall churn split?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eda",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 3, figsize=(18, 11))\nfig.patch.set_facecolor(BG)\nfig.suptitle('Customer Churn \u2014 Exploratory Data Analysis', fontsize=20,\n             color=TEXT, fontweight='bold', y=0.98)\n\n# 2a. Churn Distribution\nax = axes[0, 0]\nchurn_counts = df['Churn'].value_counts()\nbars = ax.bar(churn_counts.index, churn_counts.values,\n              color=[PALETTE[c] for c in churn_counts.index], width=0.5)\nax.set_title('Overall Churn Distribution', fontsize=13, color=TEXT, pad=10)\nax.set_ylabel('Customer Count', fontsize=11)\nfor bar, val in zip(bars, churn_counts.values):\n    pct = val / len(df) * 100\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n            f'{val:,}\\n({pct:.1f}%)', ha='center', va='bottom',\n            color=TEXT, fontsize=11, fontweight='bold')\nax.set_ylim(0, max(churn_counts.values) * 1.25)\n\n# 2b. Churn by Contract Type\nax = axes[0, 1]\ncontract_churn = df.groupby('Contract')['Churn'].apply(\n    lambda x: (x == 'Yes').mean() * 100).reset_index()\ncontract_churn.columns = ['Contract', 'ChurnRate']\ncolors = ['#EF4444' if r > 25 else '#F59E0B' if r > 15 else '#3B82F6'\n          for r in contract_churn['ChurnRate']]\nbars = ax.bar(contract_churn['Contract'], contract_churn['ChurnRate'],\n              color=colors, width=0.5)\nax.set_title('Churn Rate by Contract Type', fontsize=13, color=TEXT, pad=10)\nax.set_ylabel('Churn Rate (%)', fontsize=11)\nfor bar, val in zip(bars, contract_churn['ChurnRate']):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n            f'{val:.1f}%', ha='center', va='bottom', color=TEXT, fontsize=11, fontweight='bold')\nax.set_ylim(0, max(contract_churn['ChurnRate']) * 1.3)\n\n# 2c. Churn Rate by Tenure Group\nax = axes[0, 2]\ntenure_churn = df.groupby('TenureGroup', observed=True)['Churn'].apply(\n    lambda x: (x == 'Yes').mean() * 100)\ngradient = ['#EF4444', '#F59E0B', '#22C55E', '#3B82F6']\nbars = ax.bar(tenure_churn.index, tenure_churn.values, color=gradient, width=0.5)\nax.set_title('Churn Rate by Customer Tenure', fontsize=13, color=TEXT, pad=10)\nax.set_ylabel('Churn Rate (%)', fontsize=11)\nax.set_xlabel('Tenure Group', fontsize=11)\nfor bar, val in zip(bars, tenure_churn.values):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n            f'{val:.1f}%', ha='center', va='bottom', color=TEXT, fontsize=11, fontweight='bold')\nax.set_ylim(0, max(tenure_churn.values) * 1.3)\n\n# 2d. Monthly Charges Distribution\nax = axes[1, 0]\nfor churn_val, color in PALETTE.items():\n    subset = df[df['Churn'] == churn_val]['MonthlyCharges']\n    ax.hist(subset, bins=40, alpha=0.75, color=color, label=f'Churn={churn_val}')\nax.set_title('Monthly Charges vs Churn', fontsize=13, color=TEXT, pad=10)\nax.set_xlabel('Monthly Charges ($)', fontsize=11)\nax.set_ylabel('Count', fontsize=11)\nax.legend(facecolor='#1E293B', labelcolor=TEXT, fontsize=10)\n\n# 2e. Internet Service\nax = axes[1, 1]\ninet_churn = df.groupby('InternetService')['Churn'].apply(\n    lambda x: (x == 'Yes').mean() * 100).reset_index()\ninet_churn.columns = ['Service', 'ChurnRate']\ncolors2 = ['#EF4444' if r > 25 else '#F59E0B' if r > 15 else '#3B82F6'\n           for r in inet_churn['ChurnRate']]\nax.bar(inet_churn['Service'], inet_churn['ChurnRate'], color=colors2, width=0.5)\nax.set_title('Churn Rate by Internet Service', fontsize=13, color=TEXT, pad=10)\nax.set_ylabel('Churn Rate (%)', fontsize=11)\nfor bar, val in zip(ax.patches, inet_churn['ChurnRate']):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n            f'{val:.1f}%', ha='center', va='bottom', color=TEXT, fontsize=11, fontweight='bold')\nax.set_ylim(0, max(inet_churn['ChurnRate']) * 1.3)\n\n# 2f. Tenure vs Monthly Charges scatter\nax = axes[1, 2]\nfor churn_val, color in PALETTE.items():\n    sub = df[df['Churn'] == churn_val]\n    ax.scatter(sub['tenure'], sub['MonthlyCharges'], alpha=0.2,\n               color=color, s=8, label=f'Churn={churn_val}', edgecolors='none')\nax.set_title('Tenure vs Monthly Charges', fontsize=13, color=TEXT, pad=10)\nax.set_xlabel('Tenure (months)', fontsize=11)\nax.set_ylabel('Monthly Charges ($)', fontsize=11)\nax.legend(facecolor='#1E293B', labelcolor=TEXT, fontsize=10)\n\nplt.tight_layout()\nplt.savefig('../eda_overview.png', dpi=150, bbox_inches='tight', facecolor=BG)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-heatmap",
   "metadata": {},
   "outputs": [],
   "source": "# Correlation Heatmap\ndf_encoded = df.copy()\ndf_encoded['Churn_bin'] = (df['Churn'] == 'Yes').astype(int)\nle = LabelEncoder()\nfor col in df_encoded.select_dtypes(include='object').columns:\n    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n\nnum_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'ChargePerMonth',\n            'SeniorCitizen', 'HighValue', 'Churn_bin']\ncorr = df_encoded[num_cols].corr()\n\nfig, ax = plt.subplots(figsize=(9, 7))\nfig.patch.set_facecolor(BG)\nax.set_facecolor(BG)\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0, vmin=-1, vmax=1,\n            annot=True, fmt='.2f', ax=ax, linewidths=0.5,\n            cbar_kws={'shrink': 0.8}, annot_kws={'color': TEXT, 'fontsize': 9})\nax.set_title('Correlation Heatmap \u2014 Numerical Features', fontsize=14,\n             color=TEXT, pad=15, fontweight='bold')\nplt.setp(ax.get_xticklabels(), rotation=45, ha='right', color=TEXT, fontsize=9)\nplt.setp(ax.get_yticklabels(), rotation=0, color=TEXT, fontsize=9)\nax.figure.axes[-1].tick_params(colors=TEXT)\nplt.tight_layout()\nplt.savefig('../correlation_heatmap.png', dpi=150, bbox_inches='tight', facecolor=BG)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-3",
   "metadata": {},
   "source": "## 3. Machine Learning Models\n\n### Why Logistic Regression?\nInterpretable coefficients, fast to train, works well with standardised numerical features, and provides calibrated probabilities \u2014 ideal for business-facing churn scores.\n\n### Why Random Forest?\nHandles non-linear relationships, is robust to outliers, requires no feature scaling, and produces feature importance rankings out-of-the-box.\n\n**Evaluation split:** 80% train / 20% test, stratified by churn label."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-prep",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare feature matrix\ndf_ml = df.copy()\ndf_ml.drop(columns=['TenureGroup'], inplace=True)\n\ncat_cols = df_ml.select_dtypes(include='object').columns.tolist()\ncat_cols.remove('Churn')\n\ndf_ml = pd.get_dummies(df_ml, columns=cat_cols, drop_first=False)\ndf_ml['Churn'] = (df_ml['Churn'] == 'Yes').astype(int)\n\nX = df_ml.drop('Churn', axis=1).fillna(df_ml.drop('Churn', axis=1).median())\ny = df_ml['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y)\n\nscaler = StandardScaler()\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc  = scaler.transform(X_test)\n\nfeature_names = X.columns.tolist()\nprint(f'Train: {X_train.shape} | Test: {X_test.shape}')\nprint(f'Churn prevalence in test set: {y_test.mean():.2%}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-train",
   "metadata": {},
   "outputs": [],
   "source": "# Logistic Regression\nlr = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\nlr.fit(X_train_sc, y_train)\ny_pred_lr = lr.predict(X_test_sc)\ny_prob_lr = lr.predict_proba(X_test_sc)[:, 1]\n\n# Random Forest\nrf = RandomForestClassifier(n_estimators=200, max_depth=10,\n                             min_samples_leaf=5, random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\ny_prob_rf = rf.predict_proba(X_test)[:, 1]\n\nprint('Both models trained \u2713')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-4",
   "metadata": {},
   "source": "## 4. Model Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-metrics",
   "metadata": {},
   "outputs": [],
   "source": "def get_metrics(y_true, y_pred, y_prob, name):\n    return {\n        'Model':     name,\n        'Accuracy':  accuracy_score(y_true, y_pred),\n        'Precision': precision_score(y_true, y_pred),\n        'Recall':    recall_score(y_true, y_pred),\n        'F1':        f1_score(y_true, y_pred),\n        'ROC-AUC':   roc_auc_score(y_true, y_prob),\n    }\n\nmetrics_lr = get_metrics(y_test, y_pred_lr, y_prob_lr, 'Logistic Regression')\nmetrics_rf = get_metrics(y_test, y_pred_rf, y_prob_rf, 'Random Forest')\n\nresults_df = pd.DataFrame([metrics_lr, metrics_rf]).set_index('Model')\nresults_df.round(4)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eval-charts",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\nfig.patch.set_facecolor(BG)\nfig.suptitle('Model Performance Analysis', fontsize=20, color=TEXT, fontweight='bold', y=0.98)\n\n# Metrics bar chart\nax = axes[0, 0]\nmetric_names = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC']\nx, w = np.arange(len(metric_names)), 0.35\nlr_vals = [metrics_lr[m] for m in metric_names]\nrf_vals = [metrics_rf[m] for m in metric_names]\nax.bar(x - w/2, lr_vals, w, label='Logistic Regression', color='#3B82F6')\nax.bar(x + w/2, rf_vals, w, label='Random Forest', color='#22C55E')\nax.set_title('Model Metrics Comparison', fontsize=13, color=TEXT, pad=10)\nax.set_xticks(x); ax.set_xticklabels(metric_names, fontsize=10, rotation=20, ha='right')\nax.set_ylim(0, 1.15); ax.legend(facecolor='#1E293B', labelcolor=TEXT, fontsize=10)\nax.axhline(0.8, color='#F59E0B', linestyle='--', alpha=0.5, linewidth=1)\nfor i, (lv, rv) in enumerate(zip(lr_vals, rf_vals)):\n    ax.text(i - w/2, lv + 0.01, f'{lv:.3f}', ha='center', fontsize=8, color='#93C5FD')\n    ax.text(i + w/2, rv + 0.01, f'{rv:.3f}', ha='center', fontsize=8, color='#86EFAC')\n\n# Confusion matrices\nfor idx, (cm, title, cmap) in enumerate([\n    (confusion_matrix(y_test, y_pred_lr), 'Logistic Regression', 'Blues'),\n    (confusion_matrix(y_test, y_pred_rf), 'Random Forest',       'Greens'),\n]):\n    ax = axes[0, idx + 1]\n    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=ax, cbar=False,\n                linewidths=1, linecolor='#334155', annot_kws={'fontsize': 14, 'color': TEXT})\n    ax.set_title(f'Confusion Matrix \u2014 {title}', fontsize=12, color=TEXT, pad=10)\n    ax.set_xlabel('Predicted', fontsize=11); ax.set_ylabel('Actual', fontsize=11)\n    ax.set_xticklabels(['No Churn', 'Churn'], color=TEXT)\n    ax.set_yticklabels(['No Churn', 'Churn'], color=TEXT, rotation=0)\n\n# ROC Curves\nax = axes[1, 0]\nfor (fpr, tpr), label, color in [\n    (roc_curve(y_test, y_prob_lr)[:2], f'LR  (AUC={metrics_lr[\"ROC-AUC\"]:.3f})', '#3B82F6'),\n    (roc_curve(y_test, y_prob_rf)[:2], f'RF  (AUC={metrics_rf[\"ROC-AUC\"]:.3f})', '#22C55E'),\n]:\n    ax.plot(fpr, tpr, color=color, lw=2.5, label=label)\n    ax.fill_between(fpr, tpr, alpha=0.08, color=color)\nax.plot([0,1],[0,1], color='#475569', linestyle='--', lw=1.5)\nax.set_title('ROC Curve Comparison', fontsize=13, color=TEXT, pad=10)\nax.set_xlabel('False Positive Rate', fontsize=11)\nax.set_ylabel('True Positive Rate', fontsize=11)\nax.legend(facecolor='#1E293B', labelcolor=TEXT, fontsize=11)\n\n# Feature Importance\nax = axes[1, 1]\nfi = pd.Series(rf.feature_importances_, index=feature_names).nlargest(15)\ncolors_fi = ['#EF4444' if v > fi.quantile(0.7) else '#F59E0B' if v > fi.quantile(0.4)\n             else '#3B82F6' for v in fi.values]\nax.barh(fi.index, fi.values, color=colors_fi, height=0.7)\nax.set_title('Feature Importance \u2014 Top 15', fontsize=12, color=TEXT, pad=10)\nax.set_xlabel('Importance Score', fontsize=11); ax.invert_yaxis()\n\n# Probability Distribution\nax = axes[1, 2]\nax.hist(y_prob_rf[y_test==0], bins=40, alpha=0.7, color='#3B82F6', label='No Churn')\nax.hist(y_prob_rf[y_test==1], bins=40, alpha=0.7, color='#EF4444', label='Churn')\nax.axvline(0.5, color='#F59E0B', linestyle='--', lw=2, label='Decision (0.5)')\nax.set_title('Predicted Probability Distribution', fontsize=12, color=TEXT, pad=10)\nax.set_xlabel('Churn Probability', fontsize=11); ax.set_ylabel('Count', fontsize=11)\nax.legend(facecolor='#1E293B', labelcolor=TEXT, fontsize=10)\n\nplt.tight_layout()\nplt.savefig('../model_performance.png', dpi=150, bbox_inches='tight', facecolor=BG)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-5",
   "metadata": {},
   "source": "## 5. Feature Importance Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fi",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(12, 8))\nfig.patch.set_facecolor(BG); ax.set_facecolor('#1E293B')\nfi_all = pd.Series(rf.feature_importances_, index=feature_names).nlargest(20)\nnorm = fi_all.values / fi_all.max()\nbar_colors = [plt.cm.RdYlGn(v) for v in norm]\nbars = ax.barh(range(len(fi_all)), fi_all.values, color=bar_colors, height=0.7)\nax.set_yticks(range(len(fi_all)))\nax.set_yticklabels(fi_all.index, fontsize=10, color=TEXT)\nax.invert_yaxis()\nax.set_title('Feature Importance Analysis \u2014 Top 20 Predictors',\n             fontsize=15, color=TEXT, pad=15, fontweight='bold')\nax.set_xlabel('Importance Score', fontsize=12)\nfor bar, val in zip(bars, fi_all.values):\n    ax.text(val + 0.0005, bar.get_y() + bar.get_height()/2,\n            f'{val:.4f}', va='center', fontsize=9, color=TEXT)\nax.spines[['top','right']].set_visible(False)\nax.spines[['left','bottom']].set_color('#334155')\nplt.tight_layout()\nplt.savefig('../feature_importance.png', dpi=150, bbox_inches='tight', facecolor=BG)\nplt.show()\n\nprint('\\nTop 10 features:')\nprint(fi_all.head(10).to_string())"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-6",
   "metadata": {},
   "source": "## 6. Save Model & Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [],
   "source": "results = {\n    'churn_rate': float((df['Churn'] == 'Yes').mean()),\n    'dataset_size': int(len(df)),\n    'models': {\n        'logistic_regression': metrics_lr,\n        'random_forest':       metrics_rf,\n    },\n    'top_features': fi_all.head(15).to_dict(),\n    'churn_by_contract': df.groupby('Contract')['Churn'].apply(\n        lambda x: round((x=='Yes').mean()*100, 2)).to_dict(),\n    'churn_by_tenure': tenure_churn.to_dict(),\n    'monthly_charges_churned':  float(df[df['Churn']=='Yes']['MonthlyCharges'].mean()),\n    'monthly_charges_retained': float(df[df['Churn']=='No']['MonthlyCharges'].mean()),\n}\n\nos.makedirs('../models', exist_ok=True)\nwith open('../models/results.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\nwith open('../models/churn_model.pkl', 'wb') as f:\n    pickle.dump({'model': rf, 'scaler': scaler, 'features': feature_names}, f)\n\nprint('Model saved to ../models/churn_model.pkl \u2713')\nprint('Results saved to ../models/results.json \u2713')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-insights",
   "metadata": {},
   "source": "## 7. Business Insights & Recommendations\n\n### Key Findings\n\n| Finding | Evidence |\n|---|---|\n| Contract type is the #1 churn driver | Month-to-month: 33.2% churn vs Two-year: 8.2% |\n| New customers are highest risk | 0\u201312 months: 28.8% churn; 49\u201372 months: 15.7% |\n| Fiber optic users churn at alarming rates | 31.4% vs 6.8% for non-internet customers |\n| Electronic check = low engagement signal | 30.1% churn vs ~15% for auto-pay methods |\n| Higher-paying customers churn more | Avg $79.88/mo (churned) vs $71.12/mo (retained) |\n\n### Strategic Recommendations\n\n| Priority | Action | Estimated Impact |\n|---|---|---|\n| \ud83d\udd34 P1 | Promote 1-year & 2-year contracts with 15\u201320% discounts | \u2193 Churn by 8\u201312% |\n| \ud83d\udd34 P1 | Structured onboarding program for first 90 days | \u2193 New customer churn by ~30% |\n| \ud83d\udfe1 P2 | Address fiber optic quality & satisfaction | \u2193 Fiber churn by 5\u20138% |\n| \ud83d\udfe1 P2 | Incentivize auto-payment enrollment ($5\u201310/mo discount) | \u2193 Payment-related churn by ~40% |\n| \ud83d\udfe2 P3 | Monthly churn scoring \u2192 proactive outreach at >40% risk | Recover 15\u201325% of at-risk base |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": "# Summary printout\nprint('=' * 60)\nprint('FINAL RESULTS SUMMARY')\nprint('=' * 60)\nprint(f'  Dataset : {len(df):,} customers | Churn rate: {(df[\"Churn\"]==\"Yes\").mean():.2%}')\nprint(f'  LR  \u2014 AUC: {metrics_lr[\"ROC-AUC\"]:.4f} | F1: {metrics_lr[\"F1\"]:.4f}')\nprint(f'  RF  \u2014 AUC: {metrics_rf[\"ROC-AUC\"]:.4f} | F1: {metrics_rf[\"F1\"]:.4f}')\nprint(f'\\n  Top 5 Predictors:')\nfor feat, imp in list(fi_all.items())[:5]:\n    print(f'    {feat:40s} {imp:.4f}')\nprint(f'\\n  Avg charge \u2014 Churned: ${results[\"monthly_charges_churned\"]:.2f}')\nprint(f'  Avg charge \u2014 Retained: ${results[\"monthly_charges_retained\"]:.2f}')"
  }
 ]
}